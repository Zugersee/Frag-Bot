import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import io
import re

# --- 1. KONFIGURATION ---
st.set_page_config(page_title="Berti", page_icon="ðŸŽ“", layout="centered")

# --- 2. API KEY ---
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("API Key fehlt! Bitte in `secrets.toml` hinterlegen.")
    st.stop()
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# --- 3. SESSION STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "parts": "Hallo! Ich bin Berti. Ich bin gespannt, was wir heute erforschen. Hast du eine Frage oder eine Idee?"}
    ]
if "audio_key" not in st.session_state:
    st.session_state.audio_key = 0
if "autoplay_audio" not in st.session_state:
    st.session_state.autoplay_audio = None

# --- 4. MODELL ---
try:
    model = genai.GenerativeModel('gemini-2.0-flash')
except Exception as e:
    st.error(f"Fehler: {e}")

# --- 5. PÃ„DAGOGISCHES PROFIL (FORSCHER-MODUS) ---
system_prompt = """
Du bist "Berti", ein Forschungs-Begleiter fÃ¼r ein 6-jÃ¤hriges Kind.
DEIN ZIEL: ErmÃ¶glichungsdidaktik & Konstruktivismus. Du lieferst keine fertigen Antworten, sondern regst das eigene Denken an.

REGELN:
1. **EMOJIS:** Im Text darfst du sparsam Emojis nutzen (zur Auflockerung).
2. **KEINE BEGRÃœSSUNG:** Steige direkt in das Thema ein.
3. **SPRACHE:** Einfach, klar, duzt das Kind.

DER PÃ„DAGOGISCHE ABLAUF:

SZENARIO A: Das Kind stellt eine NEUE FRAGE oder eine HYPOTHESE.
-> **AKTION:** Gib KEINE ErklÃ¤rung. Validiere die Frage ("Spannende Idee!").
-> **FORSCHERFRAGE:** Stelle eine Frage zurÃ¼ck, die das Kind auf die LÃ¶sung bringt. Nutze Analogien aus dem Kinderalltag.
   *Beispiel:* Kind: "Warum schwimmt das Schiff?" -> Berti: "Gute Frage! Hast du mal versucht, einen schweren Stein und einen groÃŸen Ball ins Wasser zu legen? Was passiert da?"

SZENARIO B: Das Kind antwortet/rÃ¤t oder lÃ¶st das RÃ¤tsel.
-> **AKTION:** Lob den Denkprozess!
-> **WISSEN:** Jetzt darfst du das Fachwissen kurz auflÃ¶sen (max. 3 SÃ¤tze). Fachbegriffe **fett**.
-> **TRANSFER:** Stelle eine neue Frage, die das Wissen erweitert.

SZENARIO C: Geschichten & Witze
-> Geschichten: Der Held (Kind) lÃ¶st Probleme durch Nachdenken & Empathie. Ende mit Reflexionsfrage: "Was hÃ¤ttest du getan?"
"""

# --- 6. HILFSFUNKTIONEN ---

def clean_text_for_audio(text):
    """
    Entfernt Emojis und Markdown fÃ¼r eine saubere Sprachausgabe.
    """
    # 1. Entferne Markdown (*, #, _)
    text = text.replace("*", "").replace("#", "").replace("_", "")
    
    # 2. Entferne Emojis (Regex behÃ¤lt nur Buchstaben, Zahlen & Satzzeichen)
    # Erlaubt: Wortzeichen, Leerzeichen, Satzzeichen (. , ? ! : ; -) und deutsche Umlaute
    text = re.sub(r'[^\w\s,?.!Ã¤Ã¶Ã¼Ã„Ã–ÃœÃŸ:;â€“-]', '', text)
    
    return text.strip()

# --- 7. UI-LAYOUT (BUTTONS OBEN) ---

st.title("ðŸŽ“ Frag Berti")

# Die Buttons ganz oben, damit sie immer sichtbar sind
col1, col2, col3 = st.columns(3)
trigger_witz = col1.button("ðŸ¤£ Witz", use_container_width=True)
trigger_fakt = col2.button("ðŸ¦ Forschertipp", use_container_width=True)
trigger_geschichte = col3.button("ðŸ¦¸ Geschichte", use_container_width=True)

st.markdown("---")

# --- 8. CHAT VERLAUF ANZEIGEN ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["parts"])

# --- 9. AUDIO PLAYER (BUG FIX) ---
# Wir spielen Audio NUR ab, wenn es Daten gibt UND wir gerade NICHT aufnehmen.
# Das 'autoplay=True' sorgt fÃ¼r sofortiges Abspielen.
if st.session_state.autoplay_audio:
    st.audio(st.session_state.autoplay_audio, format='audio/mpeg', autoplay=True)
    # WICHTIG: Sofort leeren, damit es beim nÃ¤chsten Klick (z.B. auf Mikrofon) nicht nochmal spielt
    st.session_state.autoplay_audio = None 

# --- 10. EINGABE BEREICH ---

# Kleiner Abstand
st.write("") 
st.write("### ðŸŽ™ï¸ Deine Forschungs-Frage:")

# A) AUDIO EINGABE
# Der Key sorgt dafÃ¼r, dass das Widget resettet wird nach der Verarbeitung
audio_value = st.audio_input("Aufnahme starten:", key=f"rec_{st.session_state.audio_key}")

# B) TEXT EINGABE (Fallback)
text_input = st.chat_input("Oder schreibe hier...")

# --- 11. VERARBEITUNGSLOGIK ---

user_content = None
content_type = None 
prompt_instruction = ""

# PrioritÃ¤ten prÃ¼fen
if trigger_witz:
    user_content = "ErzÃ¤hle mir einen Witz, aber lass mich erst raten wie er ausgeht."
    content_type = "text"
elif trigger_fakt:
    user_content = "Nenne mir ein Natur-PhÃ¤nomen. ErklÃ¤re es NICHT. Frage mich stattdessen, wie das wohl funktioniert."
    content_type = "text"
elif trigger_geschichte:
    user_content = "ErzÃ¤hle eine Geschichte Ã¼ber ein Kind, das ein Problem durch Empathie lÃ¶st. Frage mich am Ende, was ich getan hÃ¤tte."
    content_type = "text"
elif audio_value:
    user_content = audio_value
    content_type = "audio"
elif text_input:
    user_content = text_input
    content_type = "text"

if user_content:
    
    # Bug-Fix VorsichtsmaÃŸnahme:
    # Wenn wir neuen Content verarbeiten, sicherstellen, dass altes Audio weg ist.
    st.session_state.autoplay_audio = None

    # 1. UI Update (User Message anzeigen)
    with st.chat_message("user"):
        if content_type == "audio":
            st.write("ðŸŽ¤ *(Sprachnachricht)*")
            user_msg_log = "ðŸŽ¤ *(Sprachnachricht)*"
            user_data_part = {"mime_type": "audio/wav", "data": user_content.getvalue()}
            prompt_instruction = "HÃ¶re dir das Kind genau an. Antworte pÃ¤dagogisch (Szenario A oder B):"
        else:
            st.markdown(user_content)
            user_msg_log = user_content
            user_data_part = user_content
            prompt_instruction = "Antworte auf diesen Text:"

    st.session_state.messages.append({"role": "user", "parts": user_msg_log})

    # 2. Kontext holen
    last_bot_response = ""
    for msg in reversed(st.session_state.messages):
        if msg["role"] == "model":
            last_bot_response = msg["parts"]
            break

    # 3. KI Generierung
    with st.spinner('Berti Ã¼berlegt...'):
        try:
            prompt_content = [
                system_prompt,
                f"KONTEXT (Deine letzte Aussage war): {last_bot_response}.",
                prompt_instruction,
                user_data_part
            ]

            response = model.generate_content(prompt_content)
            
            if response:
                bot_text = response.text
                
                # Text anzeigen
                st.session_state.messages.append({"role": "model", "parts": bot_text})
                # Kein st.markdown() hier nÃ¶tig, der Rerun macht das gleich
                
                # 4. AUDIO BEREINIGEN & GENERIEREN
                clean_text = clean_text_for_audio(bot_text)
                
                tts = gTTS(text=clean_text, lang='de')
                audio_fp = io.BytesIO()
                tts.write_to_fp(audio_fp)
                
                # Audio in Session State laden
                st.session_state.autoplay_audio = audio_fp.getvalue()
                
                # CRITICAL: Key erhÃ¶hen -> Das Audio-Input Widget wird komplett neu geladen
                # Das verhindert, dass die alte Aufnahme im Widget kleben bleibt.
                st.session_state.audio_key += 1
                
                st.rerun()

        except Exception as e:
            st.error(f"Ein Fehler ist aufgetreten: {e}")
